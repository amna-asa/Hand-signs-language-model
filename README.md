# Hand-signs-language-model

This project focuses on American Sign Language (ASL) hand gesture recognition using several popular deep learning architectures in PyTorch. The models are trained on a 29-class dataset (Aâ€“Z, 'del', 'nothing', 'space') using transfer learning techniques.

## ğŸ” Models Trained
The following pre-trained models were fine-tuned:
- **AlexNet**
- **VGG16**
- **GoogLeNet**
- **Vision Transformer (ViT-B/16)**

## ğŸ“ Dataset

I use the official **ASL Alphabet dataset** from Kaggle by *grassknoted*, which contains ~87,000 labeled images categorized into 29 classes (Aâ€“Z, del, nothing, space):  
ğŸ“¦ [ASL Alphabet Dataset â€“ Kaggle](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)


## âš™ï¸ Key Features

- Data Augmentation: Random horizontal flips, rotations
- Image Normalization using ImageNet mean/std
- Transfer Learning with layer freezing & fine-tuning
- Learning Rate Scheduler (`ReduceLROnPlateau`)
- Early stopping based on validation loss
- Graph generation for accuracy/loss
- Confusion matrix visualization

## ğŸ§  Transfer Learning Details

| Model      | Layers Unfrozen     | Pretrained on | Fine-tuned Layers         |
|------------|---------------------|---------------|---------------------------|
| AlexNet    | Classifier only     | ImageNet      | `classifier[-1]`          |
| VGG16      | Classifier only     | ImageNet      | `classifier[-1]`          |
| GoogLeNet  | FC layer only       | ImageNet      | `fc`                      |
| ViT-B/16   | Head initially      | ImageNet      | `heads.head` â†’ full model |

## ğŸ“ˆ Results Summary

| Model      | Validation Accuracy | Best Val Loss |
|------------|---------------------|---------------|
| **AlexNet**    | âœ… 99.98%             | ğŸ“‰ 0.02%         |
| **VGG16**      | âœ… 3.39%              | ğŸ“‰ 96.61%        |
| **GoogLeNet**  | âœ… 100.0%             | ğŸ“‰ 0.00%         |
| **ViT-B/16**   | âœ… 99.91%             | ğŸ“‰ 0.09%         |



